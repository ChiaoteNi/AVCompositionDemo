//
//  ParallelPlayMetalRenderer.swift
//  VideoCompositionDemo
//
//  Created by Chiaote Ni on 2022/11/28.
//

import Foundation
import MetalKit

// Metal’s textures originate in the top-left corner.
// The coordinates within the texture are normalized and always within the range of 0->1
// More information you can see the in chapter 1.6 - Metal Coordinate Systems in the following document:
// https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf
// Especially the Figure 1 and Figure 3

fileprivate class PixelBuffers {
    let outputBuffer: CVPixelBuffer
    let sourceBuffers: [CVPixelBuffer]

    init(outputBuffer: CVPixelBuffer, sourceBuffers: [CVPixelBuffer]) {
        self.outputBuffer = outputBuffer
        self.sourceBuffers = sourceBuffers
    }
}

final class ParallelPlayMetalRenderer {

    /// A `MTLDevice` object instance representing a GPU that can execute commands.
    let device: MTLDevice

    /// A `MTLCommandQueue` object used to queue the command buffers for the Metal device to execute.
    let commandQueue: MTLCommandQueue

    /// The default library contains all of the shader functions that were compiled into our app bundle.
    let library: MTLLibrary

    /// Object used to retain the buffers for rendering of textures associated with video frames.
    private var currentPixelBuffers: PixelBuffers?

    init?() {
        // Ask for the default Metal device; this represents our GPU.
        guard let device = MTLCreateSystemDefaultDevice() else {
            print("Metal is not supported on this device.")
            return nil
        }
        guard let commandQueue = device.makeCommandQueue() else {
            print("commandQueue create failed.")
            return nil
        }
        guard let library = device.makeDefaultLibrary() else {
            print("library not exist.")
            return nil
        }
        self.device = device
        // Create the command queue to submit work to the GPU.
        self.commandQueue = commandQueue
        self.library = library
    }

    func renderPixelBuffer(
        _ outputBuffer: CVPixelBuffer,
        sources pixelBuffers: [CVPixelBuffer]
    ) {
        let outputTexture = makeTexture(with: outputBuffer)
        let textures = pixelBuffers.compactMap { makeTexture(with: $0) }

        guard let outputTexture = outputTexture, !textures.isEmpty else {
            return
        }
        // Hold the texture until finish rendering.
        // This is because metal won't increase the retain count for the textures while rendering, so we need to do this by ourselves
        currentPixelBuffers = PixelBuffers(
            outputBuffer: outputBuffer,
            sourceBuffers: pixelBuffers
        )

        // set up the collection of attachments used as the rendering destination for pixels generated by a rendering pass.
        // in this case, we only need one rendering destination at the same time
        let renderPassDescriptor = MTLRenderPassDescriptor()
        renderPassDescriptor.colorAttachments[0].texture = outputTexture
        renderPassDescriptor.colorAttachments[0].loadAction = .load // demo this with only 3 video

        guard
            let commandBuffer = commandQueue.makeCommandBuffer(),
            let renderEncoder = commandBuffer.makeRenderCommandEncoder(descriptor: renderPassDescriptor),
            let vertexFunction = library.makeFunction(name: "vertex_point_func"),
            let fragmentFunction = library.makeFunction(name: "fragment_point_func")
        else {
            return
        }

        // Set up the rendering configuration state to use during a rendering pass
        let pipelineDescriptor = MTLRenderPipelineDescriptor()
        pipelineDescriptor.vertexFunction = vertexFunction
        pipelineDescriptor.fragmentFunction = fragmentFunction
        pipelineDescriptor.colorAttachments[0].pixelFormat = .bgra8Unorm

        do {
            let pipelineState = try device.makeRenderPipelineState(descriptor: pipelineDescriptor)
            // position video with vertexes
            textures
                .enumerated()
                .forEach { offset, texture in
                    // defined how to render the target texture
                    let vertexes = makeVertexes(for: offset)
                    let textureCoords = makeTextureCoordinate(for: offset)

                    renderTexture(
                        texture,
                        with: renderEncoder,
                        vertexes: vertexes,
                        textureCoords: textureCoords,
                        pipelineState: pipelineState
                    )
                }
        } catch {
            debugPrint("💥", error)
        }
        renderEncoder.endEncoding()
        commandBuffer.commit()
    }
}

extension ParallelPlayMetalRenderer {

    private func makeVertexes(for index: Int) -> [Float] {
        // Generally, you should calculate the vertexes with both the video amount and the index.
        // Like separate them into different columns and rows, then calculate the vertexes of those columns and rows
        // However, this project was made for learning, so I hard-coded them into 4 different positions.
        // Then show the vertexes in value to avoid everyone needing to spend time understanding the algorithms about calculating the position with video assets amount.
        // ⬇️ Note: For the above reason, you should calculate the vertexes with the video assets count, but not do like the following one.
        switch index {
        case 0: // top-left
            return ([
                0, 1, 0, 1,
                -1, 1, 0, 1,
                -1, 0, 0, 1,
                0, 1, 0, 1,
                -1, 0, 0, 1,
                0, 0, 0, 1,
            ])
        case 1: // top-right
            return ([
                1, 1, 0, 1,
                0, 1, 0, 1,
                0, 0, 0, 1,
                1, 1, 0, 1,
                0, 0, 0, 1,
                1, 0, 0, 1,
            ])
        case 2: // bottom-left
            return ([
                0, 0, 0, 1,
                -1, 0, 0, 1,
                -1, -1, 0, 1,
                0, 0, 0, 1,
                -1, -1, 0, 1,
                0, -1, 0, 1,
            ])
        default:
            return ([
                1, 0, 0, 1,
                0, 0, 0, 1,
                0, -1, 0, 1,
                1, 0, 0, 1,
                0, -1, 0, 1,
                1, -1, 0, 1,
            ])
        }
    }

    private func makeTextureCoordinate(for index: Int) -> [Float] {
        // Like the descriptions in makeVertexes, the following code I just made for the demo.
        // I highly recommend that everyone should calculate the `texture coordinate`
        // with some condition like orientation, but not just do like the following one.
        switch index {
        case 3:
            return [
                0, 0,
                0, 1,
                1, 1,
                0, 0,
                1, 1,
                1, 0
            ]
        default:
            return [
                1, 0,
                0, 0,
                0, 1,
                1, 0,
                0, 1,
                1, 1
            ]
        }
    }

    private func makeTexture(with pixelBuffer: CVPixelBuffer) -> MTLTexture? {
        let textureWidth = CVPixelBufferGetWidth(pixelBuffer)
        let textureHeight = CVPixelBufferGetHeight(pixelBuffer)

        let descriptor = MTLTextureDescriptor.texture2DDescriptor(
            pixelFormat: .bgra8Unorm,
            width: textureWidth,
            height: textureHeight,
            mipmapped: false
        )
        // Set up this because Metal can optimize operations for a given texture, based on its intended use.
        descriptor.usage = [
            .renderTarget,  // Declare this if we need set up texture to the colorAttachment[0]
            .shaderRead     // Declare this if we need to use texture in the shader function.
        ]

        guard
            // IOSurface is a high-level abstraction around shared memory:
            // • Very efficient cross-process and cross-API data sharing
            // • Integrated directly into GPU software stack
            // • Hides details about moving data between CPU and GPUs
            let ioSurface = CVPixelBufferGetIOSurface(pixelBuffer)?.takeUnretainedValue(), // In our demo, we've already retain all the pixelBuffer by ourselves
            let texture = device.makeTexture(
                descriptor: descriptor,
                iosurface: ioSurface,
                plane: 0
            )
        else {
            return nil
        }
        return texture
    }

    private func renderTexture(
        _ texture: MTLTexture,
        with renderEncoder: MTLRenderCommandEncoder,
        vertexes: [Float],
        textureCoords: [Float],
        pipelineState: MTLRenderPipelineState
    ) {
        // Set the current render pipeline state object.
        renderEncoder.setRenderPipelineState(pipelineState)

        // This is the same as create buffer with `setVertexBuffer`, then call setVertexBuffer(_:offset:index:)
        // The method `setVertexBytes` avoids the overhead of creating a buffer to store your data; instead, Metal manages the data.
        // Use this method for single-use data smaller than 4 KB
        renderEncoder.setVertexBytes(
            vertexes,
            length: vertexes.count * MemoryLayout<Float>.size,
            index: 0
        )
        renderEncoder.setVertexBytes(
            textureCoords,
            length: textureCoords.count * MemoryLayout<Float>.size,
            index: 1
        )

        // Set a texture for the fragment shader function.
        renderEncoder.setFragmentTexture(texture, index: 0)

        // 🖌
        // Tell the render context we want to draw our primitives (triangle strip).
        renderEncoder.drawPrimitives(
            type: .triangleStrip,
            vertexStart: 0,
            vertexCount: vertexes.count / 4, // The vertexes are with the four-dimensional homogenous vector
            instanceCount: 1
        )
    }
}

